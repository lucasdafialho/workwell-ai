# Guia de Treinamento de Modelos - WorkWell AI

## üìä Dados para Treinamento

### Op√ß√£o 1: Dados Sint√©ticos (Recomendado para demonstra√ß√£o)

O projeto inclui um gerador de dados sint√©ticos que cria dados realistas para treinamento:

```bash
# Gerar dados sint√©ticos
python pipelines/generate_data.py
```

Isso cria:
- `data/raw/checkins.csv`: ~9.000 check-ins de 50 usu√°rios ao longo de 180 dias
- `data/raw/interactions.csv`: Dados de intera√ß√µes com recomenda√ß√µes

**Caracter√≠sticas dos dados sint√©ticos:**
- Padr√µes realistas de stress, sono e trabalho
- Sazonalidade semanal e mensal
- Tend√™ncias temporais (melhorando/piorando/est√°vel)
- Valores faltantes simulados
- Correla√ß√µes entre vari√°veis

### Op√ß√£o 2: Dados Reais do Banco de Dados

Para usar dados reais do WorkWell:

1. **Exportar dados do banco PostgreSQL:**
```sql
-- Exportar check-ins
COPY (
    SELECT 
        id, usuario_id, data_checkin, nivel_stress, 
        horas_trabalhadas, horas_sono, sentimento, 
        observacoes, score_bemestar
    FROM checkins_diarios
    ORDER BY usuario_id, data_checkin
) TO '/caminho/para/data/raw/checkins.csv' WITH CSV HEADER;
```

2. **Salvar em `data/raw/checkins.csv`**

3. **Executar pipeline ETL:**
```bash
python pipelines/etl_pipeline.py
```

## üöÄ Treinamento dos Modelos

### Treinar Todos os Modelos (Recomendado)

```bash
# Treinar tudo de uma vez (gera dados se necess√°rio)
python pipelines/train_all.py

# Ou pular gera√ß√£o de dados se j√° existirem
python pipelines/train_all.py --skip-data
```

### Treinar Modelos Individuais

#### 1. Modelo de Predi√ß√£o de Burnout (LSTM)

```bash
# Com dados padr√£o
python pipelines/train_burnout.py

# Com dados customizados
python pipelines/train_burnout.py \
    --data data/raw/meus_checkins.csv \
    --output models/storage/meu_modelo.pt \
    --epochs 100 \
    --batch-size 64
```

**Requisitos:**
- Dados de check-ins com pelo menos 30 dias por usu√°rio
- M√≠nimo de 10-20 usu√°rios recomendado
- Colunas necess√°rias: `usuario_id`, `data_checkin`, `nivel_stress`, `horas_trabalhadas`, `horas_sono`, `score_bemestar`

**Tempo estimado:** 10-30 minutos (depende do hardware)

#### 2. Modelo de An√°lise de Sentimento (BERT)

```bash
python pipelines/train_sentiment.py
```

**Nota:** O modelo BERT j√° vem pr√©-treinado. Este script apenas valida e prepara o modelo.

**Para fine-tuning com dados espec√≠ficos:**
- Use o notebook `notebooks/sentiment_finetuning.ipynb` (criar se necess√°rio)
- Requer dataset de textos rotulados em portugu√™s

#### 3. Sistema de Recomenda√ß√£o

```bash
python pipelines/train_recommendation.py
```

**Requisitos:**
- Dados de intera√ß√µes: `user_id`, `item_id`, `rating`, `timestamp`
- M√≠nimo de 100-200 intera√ß√µes recomendado

**Nota:** O sistema melhora continuamente com feedback dos usu√°rios.

## üìã Checklist de Treinamento

- [ ] Dados dispon√≠veis em `data/raw/`
- [ ] Ambiente virtual ativado
- [ ] Depend√™ncias instaladas (`pip install -r requirements.txt`)
- [ ] GPU dispon√≠vel (opcional, mas recomendado para LSTM)
- [ ] Espa√ßo em disco suficiente (~500MB para modelos)

## üîß Configura√ß√µes Avan√ßadas

### Ajustar Hiperpar√¢metros do LSTM

Edite `models/burnout/lstm_model.py`:

```python
predictor = BurnoutPredictor(config={
    'hidden_size': 256,      # Tamanho da camada oculta
    'num_layers': 3,         # N√∫mero de camadas LSTM
    'dropout': 0.4           # Taxa de dropout
})
```

### Usar GPU para Treinamento

O c√≥digo detecta automaticamente GPU se dispon√≠vel. Para for√ßar CPU:

```python
# Em lstm_model.py
self.device = torch.device('cpu')
```

### Treinar com Menos Dados

Para datasets pequenos, ajuste:
- `sequence_length`: Reduzir de 30 para 15-20
- `batch_size`: Reduzir para 16 ou 8
- `epochs`: Aumentar para compensar

## üìä Monitoramento do Treinamento

### Durante o Treinamento

O script mostra:
- Loss e accuracy por √©poca
- Early stopping autom√°tico
- Melhor modelo salvo automaticamente

### Ap√≥s o Treinamento

Verifique:
- `models/storage/best_burnout_model.pt`: Modelo treinado
- Logs em console: M√©tricas finais
- MLflow (se configurado): Experimentos registrados

## üêõ Troubleshooting

### Erro: "Dados insuficientes"
- **Solu√ß√£o:** Gere mais dados ou reduza `sequence_length`

### Erro: "Out of memory"
- **Solu√ß√£o:** Reduza `batch_size` ou `sequence_length`

### Erro: "Modelo n√£o converge"
- **Solu√ß√£o:** Ajuste learning rate ou adicione mais dados

### Erro: "CUDA out of memory"
- **Solu√ß√£o:** Use CPU ou reduza batch_size

## üìà Pr√≥ximos Passos Ap√≥s Treinamento

1. **Validar modelo:**
```bash
python -c "from models.burnout.lstm_model import BurnoutPredictor; p = BurnoutPredictor(); p.load_model('models/storage/best_burnout_model.pt'); print('Modelo carregado!')"
```

2. **Iniciar API:**
```bash
python main.py api
```

3. **Testar predi√ß√µes:**
```bash
python main.py test
```

4. **Usar em produ√ß√£o:**
   - Integrar com backend .NET
   - Configurar monitoramento
   - Implementar retreinamento autom√°tico

## üí° Dicas

- **Dados sint√©ticos s√£o suficientes para demonstra√ß√£o**
- **Para produ√ß√£o, use dados reais do banco**
- **Treine periodicamente com novos dados**
- **Monitore performance em produ√ß√£o**
- **Use MLflow para versionamento**

## üìö Recursos Adicionais

- `ARCHITECTURE.md`: Arquitetura detalhada
- `README.md`: Vis√£o geral do projeto
- `notebooks/`: Notebooks demonstrativos
- C√≥digo comentado em todos os m√≥dulos

